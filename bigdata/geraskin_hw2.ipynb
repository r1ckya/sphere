{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №2 - Дерево решений\n",
    "## Гераськин Ярослав"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 1 ноября 2018, 06:00 \n",
    "**Штраф за опоздание:** -2 балла после 06:00 1 ноября, -4 балла после 06:00 8 ноября, -6 баллов после 06:00 15 ноября\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "Необходимо в slack создать таск в приватный чат:   \n",
    "/todo Фамилия Имя *ссылка на гитхаб* @alkhamush   \n",
    "Пример:   \n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw2.ipynb @alkhamush   \n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (4 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. В комментариях, где написано \"Что делает этот блок кода?\", ответьте на этот вопрос. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (2 балла)\n",
    "Добиться скорости работы fit такой, чтобы она была медленнее sklearn не более чем в 10 раз. Скорость проверяем на  wine и Speed Dating Data. Для ускорения используем только numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 3 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rickya/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/home/rickya/anaconda3/lib/python3.7/site-packages/pycodestyle.py:113: FutureWarning: Possible nested set at position 1\n",
      "  EXTRANEOUS_WHITESPACE_REGEX = re.compile(r'[[({] | []}),;:]')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None,\n",
    "                 sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        def f(x, y):\n",
    "            return (x ** 2 / y).sum(axis=1)\n",
    "\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - (f(l_c, l_s) + f(r_c, r_s)) / (l_s[0] + r_s[0])\n",
    "\n",
    "    def __gini_gain(self, y):\n",
    "        return 1 - ((np.bincount(y).astype(np.float) / y.size) ** 2).sum()\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        def f(x, y):\n",
    "            return ((x / y).log2() * x).nansum(axis=1)\n",
    "\n",
    "        return -(f(l_c, l_s) + f(r_c, r_s)) / (l_s[0] + r_s[0])\n",
    "\n",
    "    def __entropy_gain(self, y):\n",
    "        bc = np.bincount(y).astype(np.float) / y.size\n",
    "        return -np.nansum(bc * np.log2(bc))\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - (l_c.max(axis=1) + r_c.max(axis=1)) / (l_s[0] + r_s[0])\n",
    "\n",
    "    def __misclass_gain(self, y):\n",
    "        return 1 - np.max(np.bincount(y).astype(np.float) / y.size)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.sqrt(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        #  Что делает этот блок кода?\n",
    "        # сортирует (x, y) по x\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = self.num_class\n",
    "        # хотя бы cut_size объектов в каждом из детей\n",
    "        cut_size = np.int(self.min_samples_split / 2 - 1)\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # удаляем по cut_size примеров с каждой стороны и находим индексы,\n",
    "        # на которых происходит смена класса\n",
    "        if cut_size == 0:\n",
    "            splitted_sorted_y = sorted_y\n",
    "        else:\n",
    "            splitted_sorted_y = sorted_y[cut_size:-cut_size]\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] !=\n",
    "                                splitted_sorted_y[1:])[0] + (cut_size + 1)\n",
    "\n",
    "        if len(r_border_ids) == 0:\n",
    "            return np.inf, None\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # считаем количество элементов в каждом интервале с одним классом\n",
    "        eq_el_count = r_border_ids - np.append(np.array([cut_size]),\n",
    "                                               r_border_ids[:-1])\n",
    "        # 1 в клетке (i, j) значит что в позиции r_border_ids[i] происходит\n",
    "        # смена класса (был класс j - стал другой)\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]),\n",
    "                     sorted_y[r_border_ids - 1]] = 1\n",
    "        # умножаем строки на кол-во элементов в соответствующем интервале\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        # добавляем элементы из части (0, cut_size)\n",
    "        class_increments[0] = class_increments[0] + \\\n",
    "            np.bincount(sorted_y[:cut_size], minlength=class_number)\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # находим кол-во классов в левой и правой части разбиения\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(sorted_y,\n",
    "                                    minlength=class_number) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # считаем неопределенность для разбиений\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        # выбираем минимальную\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # возвращаем неопределенносить и порог\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        def make_leaf(y):\n",
    "            bc = np.bincount(y)\n",
    "            return (\n",
    "                self.LEAF_TYPE,\n",
    "                bc.argmax(),\n",
    "                bc.astype(np.float) / y.size\n",
    "            )\n",
    "\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            self.tree[node_id] = make_leaf(y)\n",
    "        if y.shape[0] < self.min_samples_split:\n",
    "            self.tree[node_id] = make_leaf(y)\n",
    "        if self.sufficient_share <= np.float(np.bincount(y).max()) / y.size:\n",
    "            self.tree[node_id] = make_leaf(y)\n",
    "\n",
    "        ids = self.get_feature_ids(x.shape[1])\n",
    "        thresholds = np.array([self.__find_threshold(x[:, idx], y)\n",
    "                               for idx in ids])\n",
    "\n",
    "        best = thresholds[:, 0].argmin()\n",
    "        t = thresholds[best, 1]\n",
    "\n",
    "        if t is None:\n",
    "            self.tree[node_id] = make_leaf(y)\n",
    "            return\n",
    "\n",
    "        if self.G_function == self.__gini:\n",
    "            gain_func = self.__gini_gain\n",
    "        elif self.G_function == self.__entropy:\n",
    "            gain_func = self.__entropy_gain\n",
    "        else:\n",
    "            gain_func = self.__misclass_gain\n",
    "\n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, ids[best], t)\n",
    "        if x_l.shape[0] == 0 or x_r.shape[0] == 0:\n",
    "            self.tree[node_id] = make_leaf(y)\n",
    "            return\n",
    "\n",
    "        self.tree[node_id] = (\n",
    "            self.NON_LEAF_TYPE,\n",
    "            ids[best],\n",
    "            t\n",
    "        )\n",
    "\n",
    "        self.feature_importances_[best] += gain_func(y) * y.size\n",
    "        self.feature_importances_[best] -= gain_func(y_l) * y_l.size\n",
    "        self.feature_importances_[best] -= gain_func(y_r) * y_r.size\n",
    "\n",
    "        self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1, pred_f)\n",
    "        self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1, pred_f)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1], dtype=np.float)\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= self.feature_importances_.sum()\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    wine.data,\n",
    "    wine.target,\n",
    "    test_size=0.1,\n",
    "    stratify=wine.target,\n",
    "    random_state=12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 ms, sys: 224 µs, total: 2.37 ms\n",
      "Wall time: 1.49 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 ms, sys: 105 µs, total: 18.6 ms\n",
      "Wall time: 17.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8363636363636364"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    df = df = pd.read_csv('Speed Dating Data.csv', encoding='cp1251')\n",
    "    df = df.iloc[:, :97]\n",
    "    df = df.drop(['id'], axis=1)\n",
    "    df = df.drop(['idg'], axis=1)\n",
    "    df = df.drop(['condtn'], axis=1)\n",
    "    df = df.drop(['round'], axis=1)\n",
    "    df = df.drop(['position', 'positin1'], axis=1)\n",
    "    df = df.drop(['order'], axis=1)\n",
    "    df = df.drop(['partner'], axis=1)\n",
    "    df = df.drop(['age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int',\n",
    "                  'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'dec_o', 'attr_o',\n",
    "                  'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o',\n",
    "                  'prob_o', 'met_o'], axis=1)\n",
    "    df.drop_duplicates('iid').age.isnull().sum()\n",
    "    df = df.dropna(subset=['age'])\n",
    "    df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(0)\n",
    "    df = df.drop(['field'], axis=1)\n",
    "    pd.get_dummies(df, columns=['field_cd'], prefix='field_cd', prefix_sep='=')\n",
    "    df = df.drop(['undergra'], axis=1)\n",
    "    df.loc[:, 'mn_sat'] = \\\n",
    "        df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "    df.loc[:, 'mn_sat'] = df.mn_sat.fillna(-999)\n",
    "    df.loc[:, 'tuition'] = \\\n",
    "        df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "    df.loc[:, 'tuition'] = df.tuition.fillna(-999)\n",
    "    df = df.dropna(subset=['imprelig', 'imprace'])\n",
    "    df = df.drop(['from', 'zipcode'], axis=1)\n",
    "    df.loc[:, 'income'] = \\\n",
    "        df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "    df.loc[:, 'income'] = df.loc[:, 'income'].fillna(-999)\n",
    "    df = df.dropna(subset=['date'])\n",
    "    df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(0)\n",
    "    df = df.drop(['career'], axis=1)\n",
    "    df = df.drop(['sports', 'tvsports', 'exercise', 'dining', 'museums',\n",
    "                  'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv',\n",
    "                  'theater', 'movies', 'concerts', 'music', 'shopping',\n",
    "                  'yoga'], axis=1)\n",
    "    df = df.drop(['expnum'], axis=1)\n",
    "    feat = ['iid', 'wave', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1',\n",
    "            'amb1_1', 'shar1_1']\n",
    "    temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "    temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "    df.loc[:, 'temp_totalsum'] = \\\n",
    "        df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1',\n",
    "                   'shar1_1']].sum(axis=1)\n",
    "    df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1',\n",
    "               'shar1_1']] = (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "                                         'fun1_1', 'amb1_1', 'shar1_1']].T /\n",
    "                              df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "    feat = ['iid', 'wave', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1',\n",
    "            'amb2_1', 'shar2_1']\n",
    "    temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "    temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "    df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "                                            'fun2_1', 'amb2_1', 'shar2_1']]\\\n",
    "                                   .sum(axis=1)\n",
    "    df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1',\n",
    "               'shar2_1']] = (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "                                         'fun2_1', 'amb2_1', 'shar2_1']].T /\n",
    "                              df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "    df = df.drop(['temp_totalsum'], axis=1)\n",
    "\n",
    "    for i in [4, 5]:\n",
    "        feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i),\n",
    "                'intel{}_1'.format(i), 'fun{}_1'.format(i),\n",
    "                'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "        if i != 4:\n",
    "            feat.remove('shar{}_1'.format(i))\n",
    "        df = df.drop(feat, axis=1)\n",
    "\n",
    "    df = df.drop(['wave'], axis=1)\n",
    "    df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                .drop(['gender'], axis=1).dropna()\n",
    "    df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                  .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1)\\\n",
    "                  .dropna()\n",
    "\n",
    "    df_female.columns = df_female.columns + '_f'\n",
    "    df_female = df_female.drop(['pid_f'], axis=1)\n",
    "    df_pair = df_male.join(df_female.set_index('iid_f'), on='pid', how='inner')\n",
    "    df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "    X = df_pair.iloc[:, 1:].values\n",
    "    y = df_pair.iloc[:, 0].values\n",
    "    features_names = df_pair.columns[1:]\n",
    "\n",
    "    return X, y, features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features_names = get_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 387 ms, sys: 4.21 ms, total: 391 ms\n",
      "Wall time: 97.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.31 s, sys: 7.04 ms, total: 1.32 s\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5306666666666666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5679579565056181"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_importances(names, clf, n=10):\n",
    "    ids = clf.feature_importances_.argsort()[-1:-n - 1:-1]\n",
    "    for idx in ids:\n",
    "        print(\n",
    "            'name {}, value {:0.4f}'.format(\n",
    "                names[idx],\n",
    "                clf.feature_importances_[idx]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name int_corr, value 0.0798\n",
      "name sinc1_1, value 0.0297\n",
      "name shar2_1, value 0.0276\n",
      "name career_c_f, value 0.0260\n",
      "name amb1_1_f, value 0.0248\n",
      "name amb3_1_f, value 0.0247\n",
      "name fun2_1_f, value 0.0214\n",
      "name income_f, value 0.0213\n",
      "name sinc2_1_f, value 0.0213\n",
      "name fun1_1_f, value 0.0210\n"
     ]
    }
   ],
   "source": [
    "show_importances(features_names, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name int_corr, value 0.1290\n",
      "name age_f, value 0.0502\n",
      "name attr1_1, value 0.0456\n",
      "name intel1_1_f, value 0.0417\n",
      "name imprelig_f, value 0.0400\n",
      "name age, value 0.0377\n",
      "name attr2_1_f, value 0.0374\n",
      "name tuition_f, value 0.0370\n",
      "name field_cd_f, value 0.0359\n",
      "name race, value 0.0312\n"
     ]
    }
   ],
   "source": [
    "show_importances(features_names, my_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=12)\n",
    "n_iter = 1000\n",
    "\n",
    "params = {\n",
    "    'max_depth': [None] + list(range(1, 11)),\n",
    "    'n_estimators': range(10, 51),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': range(2, 11)\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    clf,\n",
    "    param_distributions=params,\n",
    "    n_iter=n_iter,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 20, 'min_samples_split': 5, 'max_depth': 4, 'criterion': 'entropy'}\n",
      "CPU times: user 12.7 s, sys: 250 ms, total: 13 s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rs.fit(X, y)\n",
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
